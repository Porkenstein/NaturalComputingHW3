% !TEX root = BioInspired.tex

\chapter{Text Chapter 4 - Artificial Neural Networks}

\section{Problem 4.17}

Apply the MLP network trained with the backpopagation learning algorithm to solve the character recognition task in 4.4.2.

Determine a suitable network architecture and test the resultant network sensitivity to noise in the test data. Test different noise levels from 5-50\%.

\section{Network Description}

To solve this problem, we implemented a three layer neural network with 120 input nodes, 50 hidden layer nodes, and 8 output nodes. There are 120 input layer nodes so that each pixel has one node. There are 8 output nodes so the network can decide if the test image matches each of the training images independantly. It is entirely possible for the network to match a test image to multiple training images, or none. The hidden layer was more difficult to nail down. We ended up settling on 50 hidden layer nodes because it seemed to minimize the error we were seeing, but as long as there were "enough" hidden layer nodes, the exact number didn't seem to have much impact.

\section{Network Training}

The test and training data for the network were a set of 8 "images" represented by arrays of integers that were either 1, filled, or 0, unfilled. The network was trained against each of  the training set images 500 times. This wasn't a hard and fast number, but one that seemed to provide a middle ground between untrained and overtrained. Training for fewer cycles than this led to a high chance of misidentification even at low noise levels. Training for more cycles than this led to a high chance of not matching a test image to any of the training images even at low noise levels. In all cases, the network suceeded at matching the test images to the training images when no noise was present.

The training images were presented in batches, such that the network would be trained against each image once before moving on to the next set. However, the order in which the images were presented was randomized for each set.

\section{Network Testing}

The network was tested against images at noise levels between 0 and 50\%. At each noise level 1000 noisy test images were randomly generated from each training image and presented to the network. The results of the testing are shown in Appendix \ref{app:ANNTestResults}

\section{Network Performance}

The neural net performed very well at low noise levels, but at higher noise levels it rejected most of the images as not belonging to the training set. We theorize that we just didn't find the sweet spot for the number of training epochs

